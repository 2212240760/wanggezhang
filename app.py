import os
import pandas as pd
import streamlit as st
import plotly.graph_objects as go
import sqlite3
from io import BytesIO
from datetime import datetime, timedelta
import shutil
import streamlit_authenticator as stauth
import yaml
from yaml.loader import SafeLoader

# ç¡®ä¿æ•°æ®åº“ç›®å½•å­˜åœ¨
db_dir = "data"
os.makedirs(db_dir, exist_ok=True)
db_path = os.path.join(db_dir, "grid_assessment.db")

# åŠ è½½ç”¨æˆ·è®¤è¯é…ç½®
with open('config.yaml') as file:
    config = yaml.load(file, Loader=SafeLoader)

authenticator = stauth.Authenticate(
    config['credentials'],
    config['cookie']['name'],
    config['cookie']['key'],
    config['cookie']['expiry_days'],
    config['preauthorized']
)

name, authentication_status, username = authenticator.login('ç™»å½•', 'main')

if authentication_status:
    authenticator.logout('é€€å‡ºç™»å½•', 'main')
    st.write(f'æ¬¢è¿ *{name}*')

    def get_db_connection():
        """è·å–æ•°æ®åº“è¿æ¥ï¼Œæ·»åŠ å¼‚å¸¸å¤„ç†"""
        try:
            conn = sqlite3.connect(db_path)
            # ç¡®ä¿ä¸­æ–‡æ˜¾ç¤ºæ­£å¸¸
            conn.text_factory = str
            return conn
        except Exception as e:
            st.error(f"æ— æ³•è¿æ¥åˆ°æ•°æ®åº“: {e}")
            return None

    def validate_score(score):
        """éªŒè¯åˆ†æ•°æ˜¯å¦æœ‰æ•ˆ"""
        try:
            score = float(score)
            return 0 <= score <= 100
        except (ValueError, TypeError):
            return False

    def update_assessment(assessment_id, scores):
        """æ›´æ–°è¯„ä¼°æ•°æ®"""
        conn = get_db_connection()
        if conn is None:
            return False
        
        try:
            cursor = conn.cursor()
            # æ„å»ºSQLæ›´æ–°è¯­å¥
            set_clauses = ", ".join([f"{dim_to_db_col[dim]} = ?" for dim in DIMENSIONS])
            values = [scores[dim] for dim in DIMENSIONS] + [assessment_id]
            
            sql = f"UPDATE assessments SET {set_clauses} WHERE id = ?"
            cursor.execute(sql, values)
            conn.commit()
            return True
        except Exception as e:
            st.error(f"æ›´æ–°è¯„ä¼°æ•°æ®å¤±è´¥: {e}")
            conn.rollback()
            return False
        finally:
            if conn:
                conn.close()

    def get_leader_assessments(leader_id):
        """è·å–ç½‘æ ¼é•¿è¯„ä¼°æ•°æ®"""
        conn = get_db_connection()
        if conn is None:
            return []
        
        try:
            cursor = conn.cursor()
            cursor.execute(
                "SELECT * FROM assessments WHERE leader_id = ? ORDER BY date DESC",
                (leader_id,)
            )
            columns = [col[0] for col in cursor.description]
            # ç¡®ä¿å°†æŸ¥è¯¢ç»“æœè½¬æ¢ä¸ºå­—å…¸ï¼Œé¿å…ä½¿ç”¨å…ƒç»„ç´¢å¼•
            return [dict(zip(columns, row)) for row in cursor.fetchall()]
        except Exception as e:
            st.error(f"è·å–è¯„ä¼°æ•°æ®å¤±è´¥: {e}")
            return []
        finally:
            if conn:
                conn.close()

    def handle_none_scores(scores, dimensions):
        """å¤„ç†åˆ†æ•°ä¸­çš„Noneå€¼ï¼Œç¡®ä¿æ‰€æœ‰ç»´åº¦éƒ½æœ‰å€¼"""
        for dim in dimensions:
            if dim not in scores or scores[dim] is None:
                scores[dim] = 0
        return scores

    def calculate_total_score(scores, weights, dimensions):
        """è®¡ç®—ç»¼åˆå¾—åˆ†"""
        total = 0
        for dim in dimensions:
            total += scores.get(dim, 0) * weights[dim]
        return total

    def get_all_leaders(refresh=False):
        """è·å–æ‰€æœ‰ç½‘æ ¼é•¿ï¼Œæ”¯æŒå¼ºåˆ¶åˆ·æ–°ç¼“å­˜"""
        conn = get_db_connection()
        if conn is None:
            return []
        
        try:
            cursor = conn.cursor()
            cursor.execute("SELECT * FROM grid_leaders")
            columns = [col[0] for col in cursor.description]
            leaders = [dict(zip(columns, row)) for row in cursor.fetchall()]
            
            # å¼ºåˆ¶åˆ·æ–°æ—¶æ›´æ–°ç¼“å­˜
            if refresh:
                st.session_state.all_leaders = leaders
            return leaders
        except Exception as e:
            st.error(f"è·å–ç½‘æ ¼é•¿åˆ—è¡¨å¤±è´¥: {e}")
            return []
        finally:
            if conn:
                conn.close()

    # èƒ½åŠ›ç»´åº¦é…ç½®
    DIMENSIONS = [
        "ä¸“ä¸šæŠ€æœ¯èƒ½åŠ›", "æŒ‡æ ‡æŒæ§èƒ½åŠ›", "ç®¡ç†æ‰§è¡Œèƒ½åŠ›", "æ²Ÿé€šåè°ƒèƒ½åŠ›", "å¸‚åœºè¥é”€èƒ½åŠ›",
        "è¶…é•¿å·¥å•å æ¯”", "å‚¬å•ç‡", "ä¸Šé—¨åŠæ—¶ç‡", "é‡å¤æŠ•è¯‰ç‡", "ä¸‡æŠ•æ¯”",
        "è§¦ç‚¹æœåŠ¡å®¢æˆ·æ»¡æ„å æ¯”", "è´¨å·®å®¢æˆ·å æ¯”", "å®¶å®½å•ç”¨æˆ·ä¸­æ–­æ—¶é•¿", "å®¶å®½å¼±å…‰ç‡",
        "ä»»åŠ¡å·¥å•æ”¯æ’‘åŠæ—¶ç‡", "äº¤ç­äº¤åº•ç‡", "ç»ˆç«¯ç›˜ç‚¹", "äººå‘˜è¾¾æ ‡ç‡",
        "ä½é”€å æ¯”", "å•†æœºè½¬åŒ–ç‡", "å…ƒå®å®Œæˆç‡", "ç»ˆç«¯æ”¶å…¥"
    ]
    
    # å®šä¹‰æ•°æ®åº“å­—æ®µæ˜ å°„
    db_columns = [
        "professional_skill", "index_mastery", "management_execution", "communication_coordination", "marketing_ability",
        "long_work_order_ratio", "reminder_rate", "on_site_timeliness", "repeat_complaint_rate", "complaints_per_ten_thousand",
        "contact_service_satisfaction", "poor_quality_customer_ratio", "home_broadband_interrupt_duration", "home_broadband_weak_light_rate",
        "task_support_timeliness", "handover_rate", "terminal_inventory", "personnel_qualified_rate",
        "low_sales_ratio", "business_opportunity_conversion_rate", "yuanbao_completion_rate", "terminal_revenue"
    ]
    
    # åˆ›å»ºç»´åº¦åˆ°æ•°æ®åº“åˆ—çš„æ˜ å°„
    dim_to_db_col = {dim: db_col for dim, db_col in zip(DIMENSIONS, db_columns)}
    WEIGHTS = {dim: 1/len(DIMENSIONS) for dim in DIMENSIONS}
    THRESHOLDS = {
        "ä¼˜ç§€": 85,
        "è‰¯å¥½": 75,
        "åˆæ ¼": 60
    }
    
    IMPROVEMENT_TIPS = {
        "ä¸“ä¸šæŠ€æœ¯èƒ½åŠ›": ["åŠ å¼ºä¸“ä¸šæŠ€èƒ½åŸ¹è®­", "å‚ä¸æŠ€æœ¯äº¤æµæ´»åŠ¨", "è€ƒå–ç›¸å…³ä¸“ä¸šè¯ä¹¦"],
        "æŒ‡æ ‡æŒæ§èƒ½åŠ›": ["æ·±å…¥ç†è§£ä¸šåŠ¡æŒ‡æ ‡ä½“ç³»", "å®šæœŸåˆ†ææŒ‡æ ‡æ•°æ®", "åˆ¶å®šé’ˆå¯¹æ€§æå‡è®¡åˆ’"],
        "ç®¡ç†æ‰§è¡Œèƒ½åŠ›": ["ä¼˜åŒ–å·¥ä½œæµç¨‹", "åŠ å¼ºå›¢é˜Ÿåä½œ", "æé«˜æ‰§è¡ŒåŠ›å’Œå†³ç­–åŠ›"],
        "æ²Ÿé€šåè°ƒèƒ½åŠ›": ["åŠ å¼ºå›¢é˜Ÿæ²Ÿé€š", "æé«˜è·¨éƒ¨é—¨åä½œèƒ½åŠ›", "æå‡å®¢æˆ·æ²Ÿé€šæŠ€å·§"],
        "å¸‚åœºè¥é”€èƒ½åŠ›": ["å­¦ä¹ å¸‚åœºè¥é”€çŸ¥è¯†", "åˆ†æå¸‚åœºè¶‹åŠ¿", "æé«˜å®¢æˆ·å¼€å‘èƒ½åŠ›"],
        "è¶…é•¿å·¥å•å æ¯”": ["ä¼˜åŒ–å·¥å•å¤„ç†æµç¨‹", "æé«˜å·¥å•å¤„ç†æ•ˆç‡", "åŠ å¼ºå·¥å•è·Ÿè¸ªç®¡ç†"],
        "å‚¬å•ç‡": ["æé«˜æœåŠ¡è´¨é‡", "åŠæ—¶å“åº”å®¢æˆ·éœ€æ±‚", "ä¼˜åŒ–æœåŠ¡æµç¨‹"],
        "ä¸Šé—¨åŠæ—¶ç‡": ["åˆç†å®‰æ’ä¸Šé—¨æœåŠ¡æ—¶é—´", "åŠ å¼ºæœåŠ¡äººå‘˜ç®¡ç†", "æé«˜æœåŠ¡æ•ˆç‡"],
        "é‡å¤æŠ•è¯‰ç‡": ["æé«˜é—®é¢˜è§£å†³èƒ½åŠ›", "åŠ å¼ºæœåŠ¡è´¨é‡ç›‘ç£", "å»ºç«‹å®¢æˆ·åé¦ˆæœºåˆ¶"],
        "ä¸‡æŠ•æ¯”": ["æé«˜æœåŠ¡è´¨é‡", "åŠ å¼ºå®¢æˆ·å…³ç³»ç®¡ç†", "ä¼˜åŒ–æœåŠ¡æµç¨‹"],
        "è§¦ç‚¹æœåŠ¡å®¢æˆ·æ»¡æ„å æ¯”": ["æé«˜æœåŠ¡æ€åº¦", "åŠ å¼ºæœåŠ¡æŠ€èƒ½åŸ¹è®­", "å»ºç«‹å®¢æˆ·åé¦ˆæœºåˆ¶"],
        "è´¨å·®å®¢æˆ·å æ¯”": ["æé«˜æœåŠ¡è´¨é‡", "åŠ å¼ºç½‘ç»œç»´æŠ¤", "ä¼˜åŒ–ç½‘ç»œè´¨é‡"],
        "å®¶å®½å•ç”¨æˆ·ä¸­æ–­æ—¶é•¿": ["åŠ å¼ºç½‘ç»œç»´æŠ¤", "æé«˜æ•…éšœå¤„ç†æ•ˆç‡", "ä¼˜åŒ–ç½‘ç»œç»“æ„"],
        "å®¶å®½å¼±å…‰ç‡": ["åŠ å¼ºçº¿è·¯ç»´æŠ¤", "ä¼˜åŒ–å…‰è·¯è´¨é‡", "æé«˜è®¾å¤‡æ€§èƒ½"],
        "ä»»åŠ¡å·¥å•æ”¯æ’‘åŠæ—¶ç‡": ["åŠ å¼ºå›¢é˜Ÿåä½œ", "æé«˜å·¥ä½œæ•ˆç‡", "ä¼˜åŒ–ä»»åŠ¡åˆ†é…"],
        "äº¤ç­äº¤åº•ç‡": ["å»ºç«‹è§„èŒƒçš„äº¤æ¥ç­åˆ¶åº¦", "åŠ å¼ºäº¤æ¥ç­ç®¡ç†", "æé«˜å·¥ä½œresponsibility"],
        "ç»ˆç«¯ç›˜ç‚¹": ["å»ºç«‹å®Œå–„çš„ç»ˆç«¯ç®¡ç†åˆ¶åº¦", "å®šæœŸè¿›è¡Œç»ˆç«¯ç›˜ç‚¹", "æé«˜èµ„äº§ç®¡ç†æ°´å¹³"],
        "äººå‘˜è¾¾æ ‡ç‡": ["åŠ å¼ºäººå‘˜åŸ¹è®­", "å»ºç«‹è€ƒæ ¸æœºåˆ¶", "æé«˜äººå‘˜ç´ è´¨"],
        "ä½é”€å æ¯”": ["åŠ å¼ºå¸‚åœºè°ƒç ”", "ä¼˜åŒ–äº§å“ç»“æ„", "æé«˜é”€å”®èƒ½åŠ›"],
        "å•†æœºè½¬åŒ–ç‡": ["åŠ å¼ºå¸‚åœºåˆ†æ", "ä¼˜åŒ–é”€å”®ç­–ç•¥", "æé«˜é”€å”®æŠ€å·§"],
        "å…ƒå®å®Œæˆç‡": ["æ˜ç¡®ç›®æ ‡ä»»åŠ¡", "åˆ¶å®šåˆç†è®¡åˆ’", "åŠ å¼ºè¿‡ç¨‹ç®¡ç†"],
        "ç»ˆç«¯æ”¶å…¥": ["ä¼˜åŒ–äº§å“ç»“æ„", "æé«˜é”€å”®èƒ½åŠ›", "åŠ å¼ºå®¢æˆ·å…³ç³»ç®¡ç†"]
    }
    
    # åˆå§‹åŒ–æ•°æ®åº“
    def init_database():
        conn = get_db_connection()
        if conn is None:
            return
        
        try:
            cursor = conn.cursor()
            
            # åˆ›å»ºç½‘æ ¼é•¿è¡¨
            cursor.execute('''
            CREATE TABLE IF NOT EXISTS grid_leaders (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                name TEXT NOT NULL,
                area TEXT NOT NULL
            )
            ''')
            
            # åˆ›å»ºè¯„ä¼°è¡¨
            cursor.execute('''
            CREATE TABLE IF NOT EXISTS assessments (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                leader_id INTEGER NOT NULL,
                date TEXT NOT NULL,
                professional_skill REAL,
                index_mastery REAL,
                management_execution REAL,
                communication_coordination REAL,
                marketing_ability REAL,
                long_work_order_ratio REAL,
                reminder_rate REAL,
                on_site_timeliness REAL,
                repeat_complaint_rate REAL,
                complaints_per_ten_thousand REAL,
                contact_service_satisfaction REAL,
                poor_quality_customer_ratio REAL,
                home_broadband_interrupt_duration REAL,
                home_broadband_weak_light_rate REAL,
                task_support_timeliness REAL,
                handover_rate REAL,
                terminal_inventory REAL,
                personnel_qualified_rate REAL,
                low_sales_ratio REAL,
                business_opportunity_conversion_rate REAL,
                yuanbao_completion_rate REAL,
                terminal_revenue REAL,
                import_date TEXT,
                FOREIGN KEY (leader_id) REFERENCES grid_leaders (id)
            )
            ''')
            
            conn.commit()
            st.success("æ•°æ®åº“åˆå§‹åŒ–æˆåŠŸï¼")
            st.session_state.database_initialized = True
        except Exception as e:
            st.error(f"æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
            conn.rollback()
        finally:
            if conn:
                conn.close()
    
    def import_data(file):
        """å¯¼å…¥æ•°æ®æ—¶æ”¯æŒåˆ—åæ˜ å°„ï¼Œè§£å†³ç¼ºå°‘å¿…è¦åˆ—çš„é—®é¢˜"""
        if file.name.endswith('.csv'):
            # è¯»å–æ–‡ä»¶å†…å®¹ï¼Œæ£€æŸ¥æ˜¯å¦ä¸ºç©º
            content = file.read().decode('utf-8', errors='ignore')
            if not content.strip():
                st.error("ä¸Šä¼ çš„ CSV æ–‡ä»¶ä¸ºç©ºï¼Œè¯·æ£€æŸ¥æ–‡ä»¶å†…å®¹ã€‚")
                return False
            file.seek(0)  # å°†æ–‡ä»¶æŒ‡é’ˆé‡ç½®åˆ°æ–‡ä»¶å¼€å¤´
            try:
                # å…ˆå°è¯•ä½¿ç”¨ UTF-8 ç¼–ç 
                df = pd.read_csv(file, encoding='utf-8', skipinitialspace=True, skip_blank_lines=True)
            except UnicodeDecodeError:
                file.seek(0)  # é‡ç½®æ–‡ä»¶æŒ‡é’ˆ
                try:
                    # è‹¥ UTF-8 å¤±è´¥ï¼Œå°è¯• GBK ç¼–ç 
                    df = pd.read_csv(file, encoding='gbk', skipinitialspace=True, skip_blank_lines=True)
                except UnicodeDecodeError:
                    file.seek(0)  # é‡ç½®æ–‡ä»¶æŒ‡é’ˆ
                    try:
                        # è‹¥ GBK å¤±è´¥ï¼Œå°è¯• GB2312 ç¼–ç 
                        df = pd.read_csv(file, encoding='gb2312', skipinitialspace=True, skip_blank_lines=True)
                    except UnicodeDecodeError:
                        st.error("æ— æ³•è¯†åˆ«æ–‡ä»¶ç¼–ç ï¼Œè¯·ç¡®ä¿æ–‡ä»¶ç¼–ç ä¸º UTF-8ã€GBK æˆ– GB2312ã€‚")
                        return False
        elif file.name.endswith(('.xlsx', '.xls')):
            df = pd.read_excel(file)
        else:
            st.error("ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼ï¼Œè¯·ä¸Šä¼  xlsxã€xls æˆ– csv æ–‡ä»¶ã€‚")
            return False
        
        # æ£€æŸ¥ DataFrame æ˜¯å¦ä¸ºç©º
        if df.empty:
            st.error("ä¸Šä¼ çš„æ–‡ä»¶ä¸ºç©ºæˆ–æ— æ³•è§£æå‡ºæœ‰æ•ˆæ•°æ®ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶å†…å®¹ã€‚")
            return False
        
        # æ˜¾ç¤ºæ–‡ä»¶å‰å‡ è¡Œä¾›ç”¨æˆ·ç¡®è®¤
        st.subheader("æ–‡ä»¶æ•°æ®é¢„è§ˆ")
        st.write(df.head())
        
        # å®šä¹‰å¿…é¡»çš„åˆ—ï¼ˆç¨‹åºæ‰€éœ€çš„å­—æ®µï¼‰
        required_fields = ['name', 'area', 'date'] + list(dim_to_db_col.values())
        
        # è·å–æ–‡ä»¶ä¸­çš„åˆ—å
        file_columns = df.columns.tolist()
        
        # åˆ—åæ˜ å°„è®¾ç½®ç•Œé¢
        st.subheader("åˆ—åæ˜ å°„è®¾ç½®")
        st.info("è¯·å°†æ–‡ä»¶ä¸­çš„åˆ—æ˜ å°„åˆ°ç³»ç»Ÿæ‰€éœ€çš„å­—æ®µï¼Œæœªæ˜ å°„çš„å­—æ®µå°†è®¾ä¸º0")
        
        # æ˜ å°„å¿…é¡»çš„å­—æ®µï¼šname, area, date
        mapped_fields = {}
        
        # æ˜ å°„ name åˆ—
        st.write("### åŸºæœ¬ä¿¡æ¯æ˜ å°„")
        name_options = ['æ— åŒ¹é…åˆ—'] + file_columns
        mapped_fields['name'] = st.selectbox("æ˜ å°„åˆ° 'å§“å' å­—æ®µ", name_options, key="map_name")
        
        # æ˜ å°„ area åˆ—
        area_options = ['æ— åŒ¹é…åˆ—'] + file_columns
        mapped_fields['area'] = st.selectbox("æ˜ å°„åˆ° 'è¾–åŒº' å­—æ®µ", area_options, key="map_area")
        
        # æ˜ å°„ date åˆ—
        date_options = ['æ— åŒ¹é…åˆ—'] + file_columns
        mapped_fields['date'] = st.selectbox("æ˜ å°„åˆ° 'è¯„ä¼°æ—¥æœŸ' å­—æ®µ", date_options, key="map_date")
        
        # æ˜ å°„è¯„ä¼°ç»´åº¦åˆ—
        st.write("### èƒ½åŠ›è¯„ä¼°ç»´åº¦æ˜ å°„")
        for dim, db_col in dim_to_db_col.items():
            col_options = ['æ— åŒ¹é…åˆ—ï¼ˆè®¾ä¸º0ï¼‰'] + file_columns
            mapped_fields[db_col] = st.selectbox(f"æ˜ å°„åˆ° '{dim}' å­—æ®µ", col_options, key=f"map_{db_col}")
        
        # ç¡®è®¤æ˜ å°„
        if 'confirm_import' not in st.session_state:
            st.session_state.confirm_import = False
        
        if st.button("ç¡®è®¤æ˜ å°„å¹¶å¯¼å…¥", key="confirm_import_button"):
            st.session_state.confirm_import = True
        
        if st.session_state.confirm_import:
            # æ£€æŸ¥åŸºæœ¬ä¿¡æ¯æ˜¯å¦æœ‰æ˜ å°„
            if mapped_fields['name'] == 'æ— åŒ¹é…åˆ—' or mapped_fields['area'] == 'æ— åŒ¹é…åˆ—' or mapped_fields['date'] == 'æ— åŒ¹é…åˆ—':
                st.error("å§“åã€è¾–åŒºå’Œè¯„ä¼°æ—¥æœŸå¿…é¡»æ˜ å°„æœ‰æ•ˆåˆ—ï¼")
                st.session_state.confirm_import = False
                return False
            
            # å‡†å¤‡å¯¼å…¥æ•°æ®
            conn = get_db_connection()
            if conn is None:
                st.session_state.confirm_import = False
                return False
            
            try:
                with conn:  # ä½¿ç”¨ä¸Šä¸‹æ–‡ç®¡ç†å™¨è‡ªåŠ¨ç®¡ç†äº‹åŠ¡
                    cursor = conn.cursor()
                    # å¯¼å…¥ç½‘æ ¼é•¿æ•°æ®ï¼ˆå»é‡å¤„ç†ï¼‰
                    leaders_data = df.drop_duplicates(subset=[mapped_fields['name'], mapped_fields['area']])
                    for _, row in leaders_data.iterrows():
                        leader_name = row[mapped_fields['name']]
                        leader_area = row[mapped_fields['area']]
                        cursor.execute("INSERT OR IGNORE INTO grid_leaders (name, area) VALUES (?, ?)", (leader_name, leader_area))
                
                    # å¯¼å…¥è¯„ä¼°æ•°æ®ï¼Œè®°å½•å¯¼å…¥æ—¥æœŸ
                    import_date = datetime.now().strftime('%Y/%m/%d')
                    assessment_data = df.copy()
                    
                    # å¤„ç†è¯„ä¼°ç»´åº¦æ•°æ®
                    for db_col in dim_to_db_col.values():
                        file_col = mapped_fields[db_col]
                        if file_col != 'æ— åŒ¹é…åˆ—ï¼ˆè®¾ä¸º0ï¼‰':
                            # ä½¿ç”¨æ˜ å°„çš„åˆ—
                            assessment_data[db_col] = assessment_data[file_col]
                        else:
                            # æ— åŒ¹é…åˆ—ï¼Œè®¾ä¸º0
                            assessment_data[db_col] = 0
                    
                    # æ‰¹é‡å¯¼å…¥è¯„ä¼°æ•°æ®
                    for _, row in assessment_data.iterrows():
                        # æŸ¥æ‰¾ç½‘æ ¼é•¿ID
                        leader_name = row[mapped_fields['name']]
                        cursor.execute("SELECT id FROM grid_leaders WHERE name = ?", (leader_name,))
                        leader = cursor.fetchone()
                        if leader:
                            leader_id = leader[0]
                            # å¤„ç†æ—¥æœŸæ ¼å¼
                            try:
                                # å°è¯•è§£æå¤šç§å¯èƒ½çš„æ—¥æœŸæ ¼å¼
                                date_str = str(row[mapped_fields['date']])
                                if ' ' in date_str:
                                    date_obj = datetime.strptime(date_str, '%Y-%m-%d %H:%M:%S')
                                else:
                                    date_obj = datetime.strptime(date_str, '%Y-%m-%d')
                                date_value = date_obj.strftime('%Y/%m/%d')
                            except ValueError:
                                st.error(f"æ—¥æœŸæ ¼å¼é”™è¯¯: {row[mapped_fields['date']]}ï¼Œè¯·ä½¿ç”¨ 'YYYY-MM-DD' æˆ– 'YYYY-MM-DD HH:MM:SS' æ ¼å¼ã€‚")
                                st.session_state.confirm_import = False
                                return False
                            
                            values = [
                                leader_id, date_value
                            ] + [row[db_col] for db_col in dim_to_db_col.values()] + [import_date]
                            
                            columns = "leader_id, date, " + ", ".join(dim_to_db_col.values()) + ", import_date"
                            placeholders = ", ".join(["?"] * (len(dim_to_db_col) + 3))
                            cursor.execute(f"INSERT INTO assessments ({columns}) VALUES ({placeholders})", values)
                    
                    # å¼ºåˆ¶åˆ·æ–°ç½‘æ ¼é•¿åˆ—è¡¨ç¼“å­˜
                    get_all_leaders(refresh=True)
                    st.success(f"æˆåŠŸå¯¼å…¥ {len(leaders_data)} æ¡ç½‘æ ¼é•¿æ•°æ®å’Œ {len(assessment_data)} æ¡è¯„ä¼°æ•°æ®")
                    st.session_state.confirm_import = False
                    return True
            except Exception as e:
                st.error(f"æ•°æ®å¯¼å…¥å¤±è´¥: {str(e)}")
                st.session_state.confirm_import = False
                return False
            finally:
                if conn:
                    conn.close()

    def export_assessment_data(leader_id=None):
        """å¯¼å‡ºè¯„ä¼°æ•°æ®ä¸º DataFrameï¼Œæ”¯æŒæŒ‡å®šç½‘æ ¼é•¿æˆ–å…¨éƒ¨"""
        conn = get_db_connection()
        if conn is None:
            return pd.DataFrame()
        try:
            cursor = conn.cursor()
            if leader_id is not None:
                cursor.execute(
                    "SELECT a.*, g.name, g.area FROM assessments a LEFT JOIN grid_leaders g ON a.leader_id = g.id WHERE a.leader_id = ? ORDER BY a.date DESC",
                    (leader_id,)
                )
            else:
                cursor.execute(
                    "SELECT a.*, g.name, g.area FROM assessments a LEFT JOIN grid_leaders g ON a.leader_id = g.id ORDER BY a.date DESC"
                )
            rows = cursor.fetchall()
            columns = [desc[0] for desc in cursor.description]
            df = pd.DataFrame(rows, columns=columns)
            return df
        except Exception as e:
            st.error(f"å¯¼å‡ºæ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()
        finally:
            if conn:
                conn.close()

    def clear_expired_data(days=30):
        """æ¸…ç†è¶…è¿‡æŒ‡å®šå¤©æ•°çš„è¯„ä¼°æ•°æ®"""
        conn = get_db_connection()
        if conn is None:
            return False
        
        try:
            cursor = conn.cursor()
            expired_date = (datetime.now() - timedelta(days=days)).strftime('%Y/%m/%d')
            cursor.execute("DELETE FROM assessments WHERE import_date < ?", (expired_date,))
            conn.commit()
            return True
        except Exception as e:
            st.error(f"æ¸…ç†è¿‡æœŸæ•°æ®å¤±è´¥: {e}")
            conn.rollback()
            return False
        finally:
            if conn:
                conn.close()

    def to_excel(df):
        """å°† DataFrame å¯¼å‡ºä¸º Excel æ–‡ä»¶çš„äºŒè¿›åˆ¶æµ"""
        output = BytesIO()
        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
            df.to_excel(writer, index=False)
        output.seek(0)
        return output.getvalue()

    def clear_data():
        """æ¸…ç©ºæ‰€æœ‰è¯„ä¼°æ•°æ®å’Œç½‘æ ¼é•¿æ•°æ®"""
        conn = get_db_connection()
        if conn is None:
            return False
        try:
            cursor = conn.cursor()
            cursor.execute("DELETE FROM assessments")
            cursor.execute("DELETE FROM grid_leaders")
            conn.commit()
            # æ¸…ç©ºç¼“å­˜
            if 'all_leaders' in st.session_state:
                del st.session_state.all_leaders
            st.success("æ‰€æœ‰æ•°æ®å·²æˆåŠŸæ¸…ç©ºï¼")
            return True
        except Exception as e:
            st.error(f"æ¸…ç©ºæ•°æ®å¤±è´¥: {e}")
            conn.rollback()
            return False
        finally:
            if conn:
                conn.close()

    def backup_database():
        """å¤‡ä»½æ•°æ®åº“"""
        backup_dir = "backups"
        os.makedirs(backup_dir, exist_ok=True)
        backup_file = os.path.join(backup_dir, f"grid_assessment_{datetime.now().strftime('%Y%m%d%H%M%S')}.db")
        try:
            shutil.copy2(db_path, backup_file)
            st.info(f"æ•°æ®åº“å¤‡ä»½æˆåŠŸï¼Œå¤‡ä»½æ–‡ä»¶è·¯å¾„: {backup_file}")
            return True
        except Exception as e:
            st.error(f"æ•°æ®åº“å¤‡ä»½å¤±è´¥: {e}")
            return False

    # é¡µé¢æ ‡é¢˜å’Œé…ç½®
    st.set_page_config(
        page_title="ç½‘æ ¼é•¿è¯„ä¼°ç³»ç»Ÿ",
        page_icon="ğŸ“Š",
        layout="wide"
    )
    st.title("ç½‘æ ¼é•¿èƒ½åŠ›è¯„ä¼°ç³»ç»Ÿ")
    
    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    if 'all_leaders' not in st.session_state:
        st.session_state.all_leaders = get_all_leaders()
    
    # ä¾§è¾¹æ 
    with st.sidebar:
        # æ‰‹åŠ¨åˆå§‹åŒ–æ•°æ®åº“æŒ‰é’®
        if st.button("æ‰‹åŠ¨åˆå§‹åŒ–æ•°æ®åº“", key="init_db_button"):
            init_database()
            # åˆå§‹åŒ–æˆåŠŸåæ£€æŸ¥å¹¶æ¸…ç†è¿‡æœŸæ•°æ®
            if st.session_state.get('database_initialized', False):
                clear_expired_data()
            # åˆ·æ–°ç½‘æ ¼é•¿åˆ—è¡¨
            st.session_state.all_leaders = get_all_leaders(refresh=True)
        
        st.header("é€‰æ‹©è¯„ä¼°å‘¨æœŸ")
        selected_date = st.selectbox(
            "é€‰æ‹©è¯„ä¼°æ—¥æœŸ",
            ["2025å¹´6æœˆ", "2025å¹´5æœˆ", "2025å¹´4æœˆ", "2025å¹´3æœˆ"]
        )
        
        st.header("é€‰æ‹©ç½‘æ ¼é•¿")
        all_leaders = st.session_state.all_leaders
        leader_names = [leader["name"] for leader in all_leaders]
        
        # å¤„ç†æ— ç½‘æ ¼é•¿æ•°æ®çš„æƒ…å†µ
        if not leader_names:
            st.warning("æš‚æ— ç½‘æ ¼é•¿æ•°æ®ï¼Œå·²æ·»åŠ ç¤ºä¾‹æ•°æ®")
            conn = get_db_connection()
            if conn:
                try:
                    cursor = conn.cursor()
                    # æ·»åŠ ç¤ºä¾‹ç½‘æ ¼é•¿
                    cursor.execute("INSERT OR IGNORE INTO grid_leaders (name, area) VALUES (?, ?)", ("ç¤ºä¾‹ç½‘æ ¼é•¿", "ç¤ºä¾‹åŒºåŸŸ"))
                    conn.commit()
                    # åˆ·æ–°ç¼“å­˜
                    st.session_state.all_leaders = get_all_leaders(refresh=True)
                    all_leaders = st.session_state.all_leaders
                    leader_names = [leader["name"] for leader in all_leaders]
                except Exception as e:
                    st.error(f"æ·»åŠ ç¤ºä¾‹æ•°æ®å¤±è´¥: {e}")
                finally:
                    conn.close()
        
        # ç¡®ä¿ä¸‹æ‹‰èœå•ä½¿ç”¨æœ€æ–°çš„ leader_namesï¼Œå¹¶å¤„ç†é€‰æ‹©é€»è¾‘
        if 'selected_name' not in st.session_state or st.session_state.selected_name not in leader_names:
            st.session_state.selected_name = leader_names[0] if leader_names else None
        
        selected_name = st.selectbox(
            "é€‰æ‹©ç½‘æ ¼é•¿å§“å",
            leader_names,
            index=leader_names.index(st.session_state.selected_name) if st.session_state.selected_name in leader_names else 0,
            key="leader_selectbox"
        )
        st.session_state.selected_name = selected_name
        
        # æ•°æ®å¯¼å…¥æ¨¡å—
        st.header("æ•°æ®å¯¼å…¥")
        uploaded_file = st.file_uploader(
            "ä¸Šä¼  xlsxã€xls æˆ– CSV æ–‡ä»¶", 
            type=["xlsx", "xls", "csv"],
            key="file_uploader"
        )
        
        if uploaded_file is not None:
            import_data(uploaded_file)
        
        # æ•°æ®å¯¼å‡ºæ¨¡å—
        st.header("æ•°æ®å¯¼å‡º")
        export_format = st.selectbox("é€‰æ‹©å¯¼å‡ºæ ¼å¼", ["CSV", "Excel"])
        export_scope = st.selectbox("é€‰æ‹©å¯¼å‡ºèŒƒå›´", ["æŒ‡å®šç½‘æ ¼é•¿", "æ‰€æœ‰ç½‘æ ¼é•¿"])
        
        if export_scope == "æŒ‡å®šç½‘æ ¼é•¿":
            selected_leader = next((leader for leader in all_leaders if leader["name"] == selected_name), None)
            if selected_leader:
                leader_id = selected_leader["id"]
            else:
                leader_id = None
        else:
            leader_id = None
        
        # å¯¼å‡ºæ•°æ®æŒ‰é’®
        if st.button("å¯¼å‡ºæ•°æ®", key="export_data_button"):
            df = export_assessment_data(leader_id)
            if df is not None and not df.empty:
                if export_format == "CSV":
                    csv = df.to_csv(sep='\t', na_rep='nan')
                    st.download_button(
                        label="ä¸‹è½½ CSV æ–‡ä»¶",
                        data=csv,
                        file_name="assessment_data.csv",
                        mime="text/csv"
                    )
                elif export_format == "Excel":
                    excel_file = to_excel(df)
                    st.download_button(
                        label="ä¸‹è½½ Excel æ–‡ä»¶",
                        data=excel_file,
                        file_name="assessment_data.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
            else:
                st.warning("æ²¡æœ‰å¯å¯¼å‡ºçš„æ•°æ®ã€‚")
        
        # æ•°æ®æ¸…ç†æ¨¡å—
        st.header("æ•°æ®æ¸…ç†")
        retention_days = st.number_input("ä¿ç•™æ•°æ®å¤©æ•°", min_value=1, value=30)
        if st.button("æ¸…ç†è¿‡æœŸæ•°æ®", key="clear_expired_data_button"):
            if clear_expired_data(retention_days):
                st.success(f"æˆåŠŸæ¸…ç†è¶…è¿‡ {retention_days} å¤©çš„è¯„ä¼°æ•°æ®ï¼")
                # åˆ·æ–°è¯„ä¼°æ•°æ®
                if 'selected_leader' in st.session_state:
                    st.session_state.selected_leader = None
            else:
                st.error("æ¸…ç†è¿‡æœŸæ•°æ®å¤±è´¥ï¼Œè¯·é‡è¯•ã€‚")
        
        if st.button("æ¸…ç©ºæ‰€æœ‰æ•°æ®", key="clear_all_data_button"):
            if clear_data():
                st.success("æ‰€æœ‰æ•°æ®å·²æˆåŠŸæ¸…ç©ºï¼")
                # æ¸…ç©ºä¼šè¯çŠ¶æ€
                st.session_state.all_leaders = get_all_leaders()
                if 'selected_name' in st.session_state:
                    del st.session_state.selected_name
            else:
                st.error("æ•°æ®æ¸…ç©ºå¤±è´¥ï¼Œè¯·é‡è¯•ã€‚")
        
        # æ•°æ®åº“å¤‡ä»½
        if st.button("å¤‡ä»½æ•°æ®åº“", key="backup_db_button"):
            backup_database()
    
    def get_all_leaders_assessments():
        """è·å–æ‰€æœ‰ç½‘æ ¼é•¿çš„æœ€æ–°è¯„ä¼°æ•°æ®"""
        conn = get_db_connection()
        if conn is None:
            return []
        
        try:
            cursor = conn.cursor()
            cursor.execute("""
                SELECT a.*, g.name, g.area 
                FROM assessments a
                JOIN grid_leaders g ON a.leader_id = g.id
                WHERE (a.leader_id, a.date) IN (
                    SELECT leader_id, MAX(date) 
                    FROM assessments 
                    GROUP BY leader_id
                )
            """)
            columns = [col[0] for col in cursor.description]
            return [dict(zip(columns, row)) for row in cursor.fetchall()]
        except Exception as e:
            st.error(f"è·å–æ‰€æœ‰ç½‘æ ¼é•¿è¯„ä¼°æ•°æ®å¤±è´¥: {e}")
            return []
        finally:
            if conn:
                conn.close()
    
    # ä¸»ç•Œé¢å†…å®¹
    if 'selected_name' in st.session_state and st.session_state.selected_name:
        selected_leader = next((leader for leader in all_leaders if leader["name"] == st.session_state.selected_name), None)
        if selected_leader:
            leader_id = selected_leader["id"]
            assessments = get_leader_assessments(leader_id)
    
            if assessments:
                # æ‰¾åˆ°å¯¹åº”æ—¥æœŸçš„è¯„ä¼°è®°å½•ï¼Œè‹¥æ— åˆ™ä½¿ç”¨æœ€æ–°è®°å½•
                selected_assessment = next(
                    (a for a in assessments if a["date"] == selected_date),
                    assessments[0]
                )
    
                st.subheader(f"ç½‘æ ¼é•¿: {selected_leader['name']} - {selected_leader['area']}")
                st.subheader(f"è¯„ä¼°æ—¥æœŸ: {selected_assessment['date']}")
    
                # æ˜¾ç¤ºè¯„ä¼°åˆ†æ•°
                st.subheader("èƒ½åŠ›è¯„ä¼°åˆ†æ•°")
                col1, col2 = st.columns(2)
                for i, dim in enumerate(DIMENSIONS):
                    col = col1 if i < len(DIMENSIONS)/2 else col2
                    with col:
                        score = selected_assessment.get(dim_to_db_col[dim], 0)
                        st.metric(dim, f"{score:.2f}åˆ†")
    
                # è®¡ç®—ç»¼åˆå¾—åˆ†
                scores = {dim: selected_assessment.get(dim_to_db_col[dim], 0) for dim in DIMENSIONS}
                total_score = calculate_total_score(scores, WEIGHTS, DIMENSIONS)
    
                st.subheader(f"ç»¼åˆå¾—åˆ†: {total_score:.2f}åˆ†")
    
                # æ˜¾ç¤ºè¯„ä¼°ç­‰çº§
                grade = "ä¼˜ç§€" if total_score >= THRESHOLDS["ä¼˜ç§€"] else \
                        "è‰¯å¥½" if total_score >= THRESHOLDS["è‰¯å¥½"] else \
                        "åˆæ ¼" if total_score >= THRESHOLDS["åˆæ ¼"] else "å¾…æ”¹è¿›"
                st.subheader(f"è¯„ä¼°ç­‰çº§: {grade}")
    
                # æ˜¾ç¤ºå…¨é‡ç½‘æ ¼åˆ†å€¼æ’åå¯¹æ¯”
                all_assessments = get_all_leaders_assessments()
                all_scores = []
                for assessment in all_assessments:
                    scores = {dim: assessment.get(dim_to_db_col[dim], 0) for dim in DIMENSIONS}
                    total_score = calculate_total_score(scores, WEIGHTS, DIMENSIONS)
                    all_scores.append({
                        "å§“å": assessment['name'],
                        "è¾–åŒº": assessment['area'],
                        "ç»¼åˆå¾—åˆ†": total_score,
                        "è¯„ä¼°ç­‰çº§": "ä¼˜ç§€" if total_score >= THRESHOLDS["ä¼˜ç§€"] else
                                  "è‰¯å¥½" if total_score >= THRESHOLDS["è‰¯å¥½"] else
                                  "åˆæ ¼" if total_score >= THRESHOLDS["åˆæ ¼"] else "å¾…æ”¹è¿›"
                    })
    
                # æŒ‰ç»¼åˆå¾—åˆ†æ’åº
                all_scores.sort(key=lambda x: x["ç»¼åˆå¾—åˆ†"], reverse=True)
                # æ·»åŠ æ’ååˆ—
                for i, score_info in enumerate(all_scores, start=1):
                    score_info["æ’å"] = i
    
                st.subheader("å…¨é‡ç½‘æ ¼åˆ†å€¼æ’åå¯¹æ¯”")
                df = pd.DataFrame(all_scores)
                # é«˜äº®æ˜¾ç¤ºé€‰ä¸­çš„ç½‘æ ¼é•¿
                def highlight_selected(s):
                    if s["å§“å"] == selected_leader["name"]:
                        return ['background-color: yellow'] * len(s)
                    return [''] * len(s)
                st.dataframe(df.style.apply(highlight_selected, axis=1))
    
                # æ˜¾ç¤ºç½‘æ ¼å…·ä½“å¾—åˆ†ç»“æœ
                st.subheader("ç½‘æ ¼å…·ä½“å¾—åˆ†ç»“æœ")
                st.write(pd.DataFrame({
                    "ç»´åº¦": DIMENSIONS,
                    "å¾—åˆ†": [selected_assessment.get(dim_to_db_col[dim], 0) for dim in DIMENSIONS]
                }))
            else:
                st.warning("è¯¥ç½‘æ ¼é•¿æš‚æ— è¯„ä¼°æ•°æ®ã€‚")
        else:
            st.warning("æœªæ‰¾åˆ°é€‰ä¸­çš„ç½‘æ ¼é•¿æ•°æ®ã€‚")
    else:
        st.info("è¯·åœ¨ä¾§è¾¹æ é€‰æ‹©ç½‘æ ¼é•¿ã€‚")